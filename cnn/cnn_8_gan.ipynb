{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf71f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]\n",
      "tensorflow 2.6.2\n",
      "tensorflow-datasets 4.4.0\n",
      "Pillow 8.3.2\n",
      "pandas 1.3.3\n",
      "numpy 1.19.5\n",
      "scipy 1.7.1\n",
      "\n",
      "Num GPUs Available: 1\n",
      "Built with CUDA: True\n",
      "Built with GPU support: True\n"
     ]
    }
   ],
   "source": [
    "# Version Check\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "print(\"python\", sys.version)\n",
    "print(\"tensorflow\", tf.__version__)\n",
    "print(\"tensorflow-datasets\", tfds.__version__)\n",
    "print(\"Pillow\", PIL.__version__)\n",
    "print(\"pandas\", pd.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"scipy\", scipy.__version__)\n",
    "print()\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU support:\", tf.test.is_built_with_gpu_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b1614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00ae0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "img_shape = (28, 28, 1)\n",
    "z_dim = 100\n",
    "row_num = 8\n",
    "col_num = 8\n",
    "batch_size = row_num * col_num\n",
    "epoch_num = 10\n",
    "learning_rate = 0.0001\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94a6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92060e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,078,017\n",
      "Trainable params: 1,075,969\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# discriminator model\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, BatchNormalization, Dense, Reshape\n",
    "\n",
    "i = Input(shape=img_shape)\n",
    "out = Conv2D(16, 3, 2, padding='same')(i)  # num_filters, filter size(3, 3), strides(2, 2)\n",
    "out = Conv2D(32, 3, 2, padding='same')(out)\n",
    "out = Conv2D(64, 3, 2, padding='same')(out)\n",
    "out = Flatten()(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Dense(1024, activation='tanh')(out)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "d_model = Model(inputs=[i], outputs=[out])\n",
    "\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4328022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1568)              1607200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1568)              6272      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,721,665\n",
      "Trainable params: 1,718,529\n",
      "Non-trainable params: 3,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generator model\n",
    "\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, Activation\n",
    "\n",
    "i = Input(shape=(z_dim, ))\n",
    "out = Dense(1024, activation='tanh')(i)\n",
    "out = Dense(7 * 7 * 32, activation='tanh')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Reshape((7, 7, 32))(out)\n",
    "out = Conv2DTranspose(16, 3, 2, padding='same')(out)\n",
    "out = Conv2DTranspose(1, 3, 2, padding='same')(out)\n",
    "out = Activation('sigmoid')(out)\n",
    "\n",
    "g_model = Model(inputs=[i], outputs=[out])\n",
    "\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7092d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# discriminator loss function\n",
    "d_loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80eb198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8c9d67ec5348cba576ea7fe82f817c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a89cd8674584ae49098554610f6f25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d362e451821249f79b18c285f873661e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa549d459c0406e86512506b6beb324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157d73a1b573461ca8e74051dc132500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1c3cdf468a47bd8411e9446f70057b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3154327c30c84d58adbeba1343b8167d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295659d0ab4a4a91bd2290bdd445039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b84e5f19048dda07f06107b7c671c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efc5054eb0f42db81d97503bbbe5ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 완료\n"
     ]
    }
   ],
   "source": [
    "fcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('hjk_gan_mnist.avi', fcc, 1.0, (28 * row_num, 28 * col_num))\n",
    "\n",
    "batch_count =x_train.shape[0] // batch_size\n",
    "\n",
    "for e in range(epoch_num):\n",
    "    for _ in tqdm(range(batch_count)):\n",
    "        \n",
    "        z = np.random.uniform(-1.0, 1.0, (batch_size, z_dim))\n",
    "        f_img = g_model.predict(z)\n",
    "        f_label = np.zeros((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model(f_img)\n",
    "            loss = d_loss(f_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "        \n",
    "        batch_num=np.random.randint(0,  x_train.shape[0],  size=batch_size)\n",
    "        r_img = x_train[batch_num]\n",
    "        r_label = np.ones((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model(r_img)\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_img = g_model(z)\n",
    "            pred = d_model(f_img)\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = g_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))     \n",
    "        \n",
    "        sample_img = np.zeros((28*row_num, 28 * col_num))\n",
    "        f_img = np.resize(f_img, (row_num, col_num, 28, 28))\n",
    "        for i in range(row_num):\n",
    "            for j in range(col_num):\n",
    "                sample_img[i * 28:i * 28 +28, j * 28:j * 28 +28] = f_img[i, j, :, :]\n",
    "        sample_img = np.uint8(sample_img * 255.)\n",
    "        sample_img = cv2.applyColorMap(sample_img, cv2.COLORMAP_HOT)\n",
    "        out.write(sample_img)\n",
    "    \n",
    "    print(e, \"완료\")\n",
    "    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f745f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c9bc9b2890404dab6f22cfc8e6c86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8838836f4abc46cb8df6b9d8a98c7e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1071d7b409ce47728126624cdebdfee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f51992077704a6a913d78a05d7c7da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114f9c3bc8824904841ce30c1334fefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136f8de52c054d08bef4bbf5666082cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d155397f9fd4a1bafa12b5877b73bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d983a0a88bf4c54878aedde7e32f924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff061fe1000f4151bc5f79996a6473f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfb9661845f42c29764e088d782a4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 완료\n"
     ]
    }
   ],
   "source": [
    "i = tf.keras.Input(shape=img_shape)\n",
    "l_i = tf.keras.Input(shape=(1, ), dtype=tf.int32)\n",
    "l_out = tf.one_hot(l_i, class_num)\n",
    "l_out = tf.keras.layers.Dense(28*28*1)(l_out)\n",
    "l_out = tf.keras.layers.Reshape((28, 28, 1))(l_out) \n",
    "out = tf.keras.layers.Add()([i, l_out])\n",
    "out = tf.keras.layers.Conv2D(16, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Conv2D(32, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Conv2D(64, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Flatten()(out)\n",
    "out = tf.keras.layers.BatchNormalization()(out)\n",
    "out = tf.keras.layers.Dense(1024, activation='tanh')(out)\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(out)\n",
    "d_model = tf.keras.Model(inputs=[i, l_i],  outputs=[out])\n",
    "\n",
    "i=tf.keras.Input(shape=(z_dim, ))\n",
    "l_i = tf.keras.Input(shape=(1, ), dtype=tf.int32)\n",
    "l_out = tf.one_hot(l_i, class_num)\n",
    "l_out = tf.keras.layers.Dense(z_dim)(l_out)\n",
    "l_out = tf.keras.layers.Reshape((z_dim, ))(l_out) \n",
    "out = tf.keras.layers.Add()([i, l_out])\n",
    "out = tf.keras.layers.Dense(1024, activation='tanh')(out)\n",
    "out = tf.keras.layers.Dense(7*7*32, activation='tanh')(out)\n",
    "out = tf.keras.layers.BatchNormalization()(out)\n",
    "out = tf.keras.layers.Reshape((7, 7, 32))(out)\n",
    "out = tf.keras.layers.Conv2DTranspose(16, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Conv2DTranspose(1, 3, 2, padding='same')(out)\n",
    "out = tf.keras.layers.Activation('sigmoid')(out)\n",
    "g_model = tf.keras.Model(inputs=[i, l_i],  outputs=[out])\n",
    "\n",
    "fcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out=cv2.VideoWriter('cgan_mnist.avi', fcc, 10.0, (28*row_num, 28*col_num))\n",
    "\n",
    "batch_count =x_train.shape[0]//batch_size\n",
    "\n",
    "for e in range(epoch_num):\n",
    "    for _ in tqdm(range(batch_count)):\n",
    "        \n",
    "        z = np.random.uniform(-1.0, 1.0, (batch_size, z_dim))\n",
    "        f_y = np.random.randint(0, class_num, size=batch_size)\n",
    "        f_y = np.reshape(f_y, (batch_size, 1))\n",
    "        f_img = g_model.predict([z, f_y])\n",
    "        f_label = np.zeros((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model([f_img, f_y])\n",
    "            loss = d_loss(f_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "        \n",
    "        batch_num=np.random.randint(0, x_train.shape[0], size=batch_size)\n",
    "        r_img = x_train[batch_num]\n",
    "        r_y = y_train[batch_num]\n",
    "        r_label = np.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = d_model([r_img, r_y])\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = d_model.trainable_variables\n",
    "        grad = tape.gradient(loss, vars)\n",
    "        opt.apply_gradients(zip(grad, vars))\n",
    "\n",
    "        f_y=[i%class_num for i in range(batch_size)]\n",
    "        f_y = np.reshape(f_y, (batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_img = g_model([z, f_y])\n",
    "            pred = d_model([f_img, f_y])\n",
    "            loss = d_loss(r_label, pred)\n",
    "        vars = g_model.trainable_variables\n",
    "        grad = tape.gradient(loss,  vars)\n",
    "        opt.apply_gradients(zip(grad,  vars))     \n",
    "        \n",
    "        sample_img = np.zeros((28*row_num, 28*col_num))\n",
    "        f_img = np.resize(f_img, (row_num, col_num, 28, 28))\n",
    "        for i in range(row_num):\n",
    "            for j in range(col_num):\n",
    "                sample_img[i * 28:i * 28 +28, j * 28:j * 28 +28] = f_img[i, j, :, :]\n",
    "        sample_img = np.uint8(sample_img * 255.)\n",
    "        sample_img = cv2.applyColorMap(sample_img, cv2.COLORMAP_HOT)\n",
    "        out.write(sample_img)\n",
    "    \n",
    "    print(e, \"완료\")\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8400d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
