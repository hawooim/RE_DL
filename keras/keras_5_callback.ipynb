{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4040104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code allows to output more than one variable value without using a print statement.\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# # Default\n",
    "# # InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cdca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]\n",
      "tensorflow 2.6.2\n",
      "tensorflow-datasets 4.4.0\n",
      "Pillow 8.3.2\n",
      "pandas 1.3.3\n",
      "numpy 1.19.5\n",
      "scipy 1.7.1\n",
      "\n",
      "Num GPUs Available: 1\n",
      "Built with CUDA: True\n",
      "Built with GPU support: True\n"
     ]
    }
   ],
   "source": [
    "# Version Check\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "print(\"python\", sys.version)\n",
    "print(\"tensorflow\", tf.__version__)\n",
    "print(\"tensorflow-datasets\", tfds.__version__)\n",
    "print(\"Pillow\", PIL.__version__)\n",
    "print(\"pandas\", pd.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"scipy\", scipy.__version__)\n",
    "print()\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU support:\", tf.test.is_built_with_gpu_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d628f",
   "metadata": {},
   "source": [
    "## Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd985eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (60000, 28, 28) (60000,)\n",
      "test set : (10000, 28, 28) (10000,)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 221,952\n",
      "Trainable params: 221,248\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('train set:', x_train.shape, y_train.shape)\n",
    "print('test set :', x_test.shape, y_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "# Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(64), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32, activation='softmax'), \n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f636996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath='tmp_checkpoint.ckpt', \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e621d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3214 - acc: 0.9225 - val_loss: 0.1041 - val_acc: 0.9683\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10413, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1205 - acc: 0.9635 - val_loss: 0.0888 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10413 to 0.08875, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0855 - acc: 0.9733 - val_loss: 0.0674 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08875 to 0.06744, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0687 - acc: 0.9785 - val_loss: 0.0667 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06744 to 0.06670, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0604 - acc: 0.9806 - val_loss: 0.0635 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06670 to 0.06349, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0509 - acc: 0.9837 - val_loss: 0.0607 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06349 to 0.06074, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0466 - acc: 0.9848 - val_loss: 0.0741 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06074\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0390 - acc: 0.9870 - val_loss: 0.0637 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06074\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0353 - acc: 0.9883 - val_loss: 0.0594 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06074 to 0.05937, saving model to tmp_checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0341 - acc: 0.9887 - val_loss: 0.0643 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05937\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    epochs=10, verbose=1, \n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5d0471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0643 - acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06428355723619461, 0.9811000227928162]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before loading model checkpoint\n",
    "model.evaluate(x_test, y_test)  # loss(sparse_categorical_crossentropy), val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdef74b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0594 - acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05937452241778374, 0.9819999933242798]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After loading model checkpoint\n",
    "model.load_weights('tmp_checkpoint.ckpt')\n",
    "model.evaluate(x_test, y_test)  # loss(sparse_categorical_crossentropy), val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf94e1e",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3a4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (60000, 28, 28) (60000,)\n",
      "test set : (10000, 28, 28) (10000,)\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 221,952\n",
      "Trainable params: 221,248\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('train set:', x_train.shape, y_train.shape)\n",
    "print('test set :', x_test.shape, y_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "# Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(64), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32, activation='softmax'), \n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3eb9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86732ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3184 - acc: 0.9248 - val_loss: 0.1087 - val_acc: 0.9665\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1163 - acc: 0.9639 - val_loss: 0.0869 - val_acc: 0.9731\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0861 - acc: 0.9729 - val_loss: 0.0757 - val_acc: 0.9761\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0694 - acc: 0.9775 - val_loss: 0.0730 - val_acc: 0.9781\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0608 - acc: 0.9807 - val_loss: 0.0741 - val_acc: 0.9773\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0508 - acc: 0.9836 - val_loss: 0.0649 - val_acc: 0.9802\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0433 - acc: 0.9858 - val_loss: 0.0655 - val_acc: 0.9803\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0398 - acc: 0.9872 - val_loss: 0.0663 - val_acc: 0.9802\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0355 - acc: 0.9882 - val_loss: 0.0669 - val_acc: 0.9803\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    epochs=20, verbose=1,\n",
    "                    callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early-stopped after 9th epoch. (Val-loss did not decrease for 3 epochs since 6th epoch.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36255564",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8796ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (60000, 28, 28) (60000,)\n",
      "test set : (10000, 28, 28) (10000,)\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 221,952\n",
      "Trainable params: 221,248\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('train set:', x_train.shape, y_train.shape)\n",
    "print('test set :', x_test.shape, y_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "# Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(64), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32, activation='softmax'), \n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381ae037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial learning rate\n",
    "model.optimizer.lr.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e1ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    tf.print(f\"learning rate: {lr:0.5f}\")\n",
    "    \n",
    "    # for the first 5 epochs, maintain learning_rate\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    \n",
    "    # after 5 epochs, decrease learning_rate\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c43def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "learning rate: 0.00100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3102 - acc: 0.9254 - val_loss: 0.0974 - val_acc: 0.9708\n",
      "Epoch 2/10\n",
      "learning rate: 0.00100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1148 - acc: 0.9648 - val_loss: 0.0836 - val_acc: 0.9737\n",
      "Epoch 3/10\n",
      "learning rate: 0.00100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0876 - acc: 0.9730 - val_loss: 0.0706 - val_acc: 0.9759\n",
      "Epoch 4/10\n",
      "learning rate: 0.00100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0716 - acc: 0.9771 - val_loss: 0.0647 - val_acc: 0.9791\n",
      "Epoch 5/10\n",
      "learning rate: 0.00100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0570 - acc: 0.9815 - val_loss: 0.0753 - val_acc: 0.9763\n",
      "Epoch 6/10\n",
      "learning rate: 0.00100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0485 - acc: 0.9838 - val_loss: 0.0610 - val_acc: 0.9798\n",
      "Epoch 7/10\n",
      "learning rate: 0.00090\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0402 - acc: 0.9867 - val_loss: 0.0612 - val_acc: 0.9818\n",
      "Epoch 8/10\n",
      "learning rate: 0.00082\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0324 - acc: 0.9894 - val_loss: 0.0587 - val_acc: 0.9833\n",
      "Epoch 9/10\n",
      "learning rate: 0.00074\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0272 - acc: 0.9912 - val_loss: 0.0585 - val_acc: 0.9825\n",
      "Epoch 10/10\n",
      "learning rate: 0.00067\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.0573 - val_acc: 0.9841\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    epochs=10, verbose=1, \n",
    "                    callbacks=[learning_rate_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8f9cd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00061"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final learning rate\n",
    "round(model.optimizer.lr.numpy(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337669f",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b834bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (60000, 28, 28) (60000,)\n",
      "test set : (10000, 28, 28) (10000,)\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 221,952\n",
      "Trainable params: 221,248\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('train set:', x_train.shape, y_train.shape)\n",
    "print('test set :', x_test.shape, y_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "# Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(64), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32), \n",
    "    BatchNormalization(),   # BatchNorm between Dense and Activation\n",
    "    Activation('relu'),\n",
    "    Dense(32, activation='softmax'), \n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eacd57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard path\n",
    "log_dir = 'tensorboard'\n",
    "\n",
    "# define tensorboard callback \n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16822704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3101 - acc: 0.9251 - val_loss: 0.1092 - val_acc: 0.9647\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1147 - acc: 0.9656 - val_loss: 0.0859 - val_acc: 0.9728\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0873 - acc: 0.9725 - val_loss: 0.0719 - val_acc: 0.9772\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0707 - acc: 0.9777 - val_loss: 0.0729 - val_acc: 0.9782\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0587 - acc: 0.9807 - val_loss: 0.0737 - val_acc: 0.9772\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0521 - acc: 0.9834 - val_loss: 0.0665 - val_acc: 0.9799\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0445 - acc: 0.9853 - val_loss: 0.0683 - val_acc: 0.9797\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0413 - acc: 0.9858 - val_loss: 0.0642 - val_acc: 0.9811\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0358 - acc: 0.9880 - val_loss: 0.0609 - val_acc: 0.9803\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0346 - acc: 0.9882 - val_loss: 0.0639 - val_acc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    epochs=10, verbose=1, \n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ccd646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9176), started 0:07:42 ago. (Use '!kill 9176' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-12103fcdd257bbbc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-12103fcdd257bbbc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tensorboard extention\n",
    "%load_ext tensorboard\n",
    "\n",
    "# tensorboard print magic commmand\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d4b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
